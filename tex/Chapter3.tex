% !TEX root = ../thesis.tex
\chapter{基于相似性融合学习的多模态约束传播}
\section{引言}
在约束聚类的任务中，两个对象是否属于同一聚类的信息通常由成对约束表示，也称为比然连接（must-link）约束和必然不连接（cannot-link）约束。 成对约束是一种特别经济的辅助信息，尽管它不能提供任何有关类别的明确信息，但可以从用户那里通过高效的交互方式进行信息采集。

在过去的十几年的时间里，成对约束已广泛用于约束聚类和度量学习问题中。Wagstaff 等人首先在他们的工作中将成对约束引入聚类问题\cite{wagstaff2000clustering,wagstaff2001constrained}。Xing等人提出了一个具有成对约束的距离度量学习框架\cite{xing2002distance}。度量学习中的一些后续工作也证明了成对约束的作用\cite{weinberger2005distance,davis2007information}。

由于成对约束是一种特殊的弱监督信息，因此一些约束传播方法\cite{lu2008constrained,lu2010constrained,fu2011symmetric}陆续被提出以充分利用成对约束信息。Lu和Carreira-Perpinan在文献\parencite{lu2008constrained}中提出了Affinity Propagation（AP）算法，该算法通过借助高斯过程实现了约束传播。Lu和Ip在文献\parencite{lu2010constrained}中提出了Exhaustive and Efficient Constraint Propagation（E$^2$CP）方法。E$^2$CP算法在标签传播（label propagation）\cite{zhou2004learning}的学习框架下对成对约束信息进行传播，并且作者将约束信息的传播解释为半监督的二分类学习问题。作为能够有效利用辅助信息的一种有力工具，约束传播已经被广泛应用在半监督学习场景中。文献\parencite{jian2016interactive}提出了ACP Cut算法，以将用户所提供的交互式信息的特征传播到整个图像中，以用于个性化地图像分割。文献\parencite{han2016segmentation}提出了一种用于图像分割的高效的选择性约束传播方法，并且仅在图像的一个像素子集上执行约束传播。在实际应用中，由于观察到的真实信息数据的量很少，半监督学习方法经常会面临标注有缺陷的问题。Zhu等人设计了约束传播随机森林（Constraint Propagation Random Forest，COP-RF）算法\cite {zhu2016constrained}，该方法不仅能够应对由于有缺陷的标注数据产生的噪声约束，而且能够执行有效的稀疏化约束传播。文献\parencite{wang2016semi}利用成对约束传播的方法来提升半监督的非负矩阵分解的效果。Wu等人采用约束传播方法在初始化的约束信息中扩展增加更多的有用信息，以用于在视频中进行人脸的聚类和跟踪\cite{wu2017coupled}。

上述提到的约束传播方法全部是针对单模态数据集提出的。事实上，我们经常需要分析具有多模态多视图的数据集，例如文本描述和多种类型的图像特征。近年来，多模态数据的融合学习非常普遍，并且在例如多传感器系统、生物医学研究和环境研究等许多领域中有深入研究。不同模态之间的关联将为数据本身引入一种新形式的多样性。这些存在于不同的模态之间的交互信息的现象带来了新的约束类型，这种约束可以减少相应学习过程中的自由度\cite{lahat2015multimodal}。Yu等人指出，具有视觉和用户点击特征的多模态距离度量学习可以改善检索中的图像排序效果\cite{yu2017deep}。文献\parencite{kahou2016emonets}提出了EmoNets方法用于视频中的情绪识别，该EmoNets可以学习多种专家模型，每种模型仅关注一种模态。Poria等人研究了情感计算（affective computing）中的多模太融合，并制定了一种多模态情感分析框架，以实现在视频内容和其他不同模态信息中提取用户的情绪\cite{poria2017review,poria2017ensemble}。Shen等人提出了一种多模态抑郁字典学习（Multimodal Depressive Dictionary Learning，MDL）\cite{shen2017depression}方法，通过利用社交媒体中的情绪特征、用户资料特征及话题级别特征等不同模态的特征信息，以进行抑郁症检测。此外，高度类似于多模式数据融合的多视图数据融合也被广泛应用于许多实际问题的研究中，例如面部识别\cite{kan2016multi}和动作识别\cite{shao2016kernelized}。

近几年，一些以解决多模态约束传播问题的方法被先后提出\cite{fu2011multi,fu2012modalities,lu2013unified,lu2013exhaustive}。但是，这种多模态约束传播方法中大多数都是为特殊情况而设计的，即只有两种不同的模态需要处理，例如Unified Constraint Propagation（UCP）\cite{lu2013unified}算法和Multi-Source Constraint Propagation（MSCP）\cite{lu2013exhaustive}算法。经验上，我们经常可能会需要能够处理两种以上模态的算法，而上述方法在这种情况下是不适用的。
尽管文献\parencite{fu2011multi}中提出的Multi-Modal Constraint Propagation（MMCP）方法对模态的数量没有限制，但是MMCP的学习需要有每种模态的先验知识作为数据输入。这意味着我们需要手动决定每种模式的重要性。当我们有数量比较多的模态需要处理时，这样的手动设置方案几乎是不可行的。但是，MMCP依然为多模态约束传播提供了一个通用的学习框架。文献\parencite{fu2012modalities}中提出的Multi-modal Constraint Propagation（MCMCP）方法是一种更新一些的多模态约束传播方法。MCMCP在约束传播中引入了共识正则器，以迫使不同模态上的约束传播结果保持一致。

多模态学习中普遍存在的一个挑战是如何实现模态融合并有效利用多种数据模态所提供的额外信息。在本章中，我们倾向于将注意力集中在利用数据所提供的很少的监督信息进行融合相似性矩阵的学习。在多模态的标签传播问题中，监督信息是每个对象的标签，需要通过融合不同模态的相似性矩阵，以估计标签扩散的结果。然而在约束传播和标签传播之间有着一定的差异。在多模态约束传播问题中，监督信息和传播得到的结果都是相似性信息，这使得从这些不同模态的成对约束中融合出一个好的相似性矩阵变得更加直观且合理。 因此，我们可以在融合学习中充分利用多模态数据集中的成对约束，同时实现约束的传播和相似性矩阵融合的学习。

在本章中，我们提出了一种新的用于约束传播的多模态融合学习方法：Multi-modal Fusion Learning（MFL）。MFL继承了MMCP方法所提出的多模态约束传播学习框架。我们首先将一种被广泛应用于多模态聚类和标签传播问题中的多模态融合方法引入到约束传播学习框架中，在本章中，我们将该算法视为基线方法。由于我们通过从拉普拉斯正则化（Laplacian regularization）中学到的松弛后的权重系数构建此基线方法，因此我们将其称为松弛权重组合（Relaxed Weight Combination，RWC）。
实验结果表明，RWC方法所学习的融合结果可能会深陷入一些判别性较差的模态而忽视高判别性的模态。
受RWC方法的进一步启发，我们提出的MFL方法在约束传播的过程中同时从约束传播和拉普拉斯正则化这两个优化目标中学习多模式融合。从数据中观察到的成对约束可以提供少量的证据以判断一个模态的信息是否有高判别性。同时，拉普拉斯正则化可以确保具有更一致的相似性矩阵的模态将受到足够多的重视。我们提出的MFL同时还可以作为模态选择器，NFL能够自动消除没有帮助的模态，并维护一个相对稀疏的候选模态列表。

\section{约束传播背景知识}
在本节中我们首先将针对多模态约束传播对所用到的数学符号进行补充说明，然后简要回顾典型的单模态约束传播算法E$^2$CP\cite{lu2010constrained}和多模态约束传播算法MMCP\cite{fu2011multi}。
\subsection{符号说明}
在下文中，矩阵将用大写字母表示，向量和标量以写字母表示。给定矩阵$ {A} \in \mathbb{R}^{n\times m}$，$ a_{i,j} $为矩阵$A$在位置$ i,j $的元素。相似地，$ \alpha_{i} $ 为向量 $ \boldsymbol{\alpha} $的第 $ i $个元素。考虑到多模态的情况，在未特殊说明的情况下，我们在矩阵和向量中用下标$s$区分多模态数据集不同的模态，即${A}_s$表示源自模态$s$中的一个矩阵。矩阵$ {A}_s $ 中的第$ i,j $个元素被表示为$a_{i,j,s}$。
% 此外，对于矩阵$A$和矩阵$D$我们定义$ \|{A}\|_{D} = \mathrm{tr} ({A}^T{D}{A})^{\frac{1}{2}}$ 以保持文中公式的简洁。

我们用大写的花体字母表示集合和图。给定一个数据集合$\mathcal{U} = \{u_1,\dots,u_n \}$，每一个数据实例的数据被表示为$u_i$。$u_i$仅表示第$i$个数据实例本身，不代表任何数据向量或特征向量，更进一步地，我们将数据$u_i$在模态$s$上的数据特征向量表示为$u_{i,s}$。

对于第$s$个模态，我们可以在全部$n$个数据实例上通过$k$-NN热力核构建相似性矩阵$ {W}_s$:
\begin{equation}
w_{i,j} = \begin{cases} \mathrm{exp}(-\frac{\|u_{i,s}-u_{j,s}\|_{2}}{t}), \; &u_{i,s}\in\mathcal{N}_s(u_{j,s})\;\mathrm{or}\; u_{j,s}\in\mathcal{N}_k(u_{i,s});\\
0,&\mathrm{otherwise,}\end{cases}   
\label{eq3:GaussKer}                              
\end{equation}
其中$\mathcal{N}_k(u_{i,s})$为数据$u_{i,s}$在根据第$s$模态信息得到的$k$个最近邻的集合。

模态$s$上的拉普拉斯矩阵$ {L}_s $定义为$ {L}_s={D}_s-{W}_s $，此处对角矩阵
$ {D}_s \in \mathbb{R}^{n\times n}$ 通过相似性矩阵 $ {W}_s$ 构建且$ d_{i,i,s} =\sum_i w_{i,j,s}$\cite{chung1997spectral}。归一化图拉普拉斯矩阵 $ \hat{{L}} $定义为
\begin{equation}
	\hat{{L}} = {D}^{-1/2}{LD}^{-1/2}.
\end{equation}
我们将第$s$个模态的图定义为$\mathcal{G}_s = (\mathcal{U},{W}_s)$，在我们的问题表述里图$\mathcal{G}_s$等价于第$s$个模态的全部信息。

在约束传播问题中，我们可以将相似性矩阵中的成对约束看作数据点对之间的关系的标签。因此，我们可以对两类不同的约束定义两个集合。必然连接（must-link）集合$ \mathcal{M} = \{(u_i,u_j)\} $包含的数据对中$ u_i $ 和 $ u_j $属于同一个类别中。必然不连接（cannot-link）集合$ \mathcal{C} = \{(u_i,u_j)\}$元素数据对中的两个数据点属于不同标签类别。根据must-link集合和cannot-link集合，我们可以构建约束矩阵$ {Y} \in  \mathbb{R}^{n\times n}$，
\begin{equation}
y_{i,j} = 
\begin{cases}
1, \qquad&(u_i,u_j)\in \mathcal{M};\\
-1, &(u_i,u_j)\in\; \mathcal{C};\\
0, &\text{otherwise}.
\end{cases}
\label{eq3:Y}
\end{equation}

\subsection{单模态约束传播算法E$^2$CP}
E$^2$CP算法通过将标签扩散引入相似性矩阵来解决约束传播问题。
观测到的约束信息被视为数据点对之间已知的关系二分类标签，其中must-link中元素作为正样本，cannot-link的元素为负样本。
我们从公式（\ref{eq3:Y}）观察到矩阵$Y$中对应于数据$u_i$的第$i$列或第$i$行与半监督问题的问题设置非常相似。其中$ 1 $ 和 $ -1 $为半监督问题中两个不同类的类标签，大量的$0$代表未观测到的需要预测的标签。利用相似性信息，这样的半监督问题可以通过标签传播\cite{zhou2004learning}解决。

我们进一步定义约束传播的传播结果为矩阵$F$。在矩阵$Y$上的约束传播包含两个部分，即水平方向的传播和竖直方向的传播。如果我们采用矩阵$F_v$表示竖直方向的传播，则优化$F_v$的目标函数与文献\parencite{zhou2004learning}中的结论相似：
\begin{equation}
	\mathop{\mathrm{min}}_{{F}_v}\;\frac{1}{2}\eta\;\mathrm{tr}(({F}_v-{Y})^T({F}_v-{Y}))+\frac{1}{2}\mathrm{tr}({F}_v^T\hat{{L}}{F}_v), 
\end{equation}
此处，$ \eta $为正则化参数。
而传播结果$F_v$的闭式解为
\begin{equation}
	{F}_v = \eta(\eta{I}+\hat{{L}})^{-1}{Y}.
\end{equation}

相似地，如果我们以矩阵$F_h$表示水平传播的结果，我们可以将其闭式解写为
\begin{equation}
{F}_h = \eta{Y}(\eta{I}+\hat{{L}})^{-1}.
\end{equation}

如果将竖直方向传播的结果$F_v$作为水平方向传播中的初始化约束矩阵$Y$，即可实现两个方向的交替传播。则约束传播的结果矩阵$F$为
\begin{equation}
{F} = \eta^2(\eta{I}+\hat{{L}})^{-1}{Y}(\eta{I}+\hat{{L}})^{-1}
\label{eq3:e2cp}
\end{equation}

\subsection{多模态约束传播算法MMCP}
MMCP算法基于转移概率将E$^2$CP算法推广到了多模态的情况下。

对于图$\mathcal{G}_s$, 根据${W}_s$构建对角矩阵${D}_s$，其中有$d_{i,i,s} = \sum_j w_{i,j,s}$。MMCP算法将第$s$个模态的容量（volume）定义为
\begin{equation}
v_s = \sum_i d_{i,i,s} = \sum_{i,j}w_{i,j,s}.
\end{equation}

图$\mathcal{G}_s$上的转移概率可以通过条件概率计算得出：
\begin{equation}
	P(u_i\rightarrow u_j|\mathcal{G}_s) = P(u_j|u_i,\mathcal{G}_s) = \frac{w_{i,j,s}}{d_{i,i,s}}.
	\label{eq3:mmcp_trans}
\end{equation}
在给定图$\mathcal{G}_s$下数据$u_i$的概率为
\begin{equation}
P(u_i|\mathcal{G}_s) = \frac{d_{i,i,s}}{v_s}.
\label{eq3:Pulg}
\end{equation}
同时我们可以定义给定模态$\mathcal{G}_s$上的归一化相似性矩阵$\bar{W_s}$：
\begin{equation}
    \bar{w}_{i,j,s} = P(u_i, u_j|\mathcal{G}_s) = \frac{{w}_{i,j,s}}{v_s}.
    \label{eq3:jointW}
\end{equation}
公式（\ref{eq3:jointW}）给出的矩阵$\bar{W}_s$也可以被看作是由公式（\ref{eq3:mmcp_trans}）及（\ref{eq3:Pulg}）计算出的给定条件$\mathcal{G}_s$的联合概率分布表。

假设我们可以第$s$个模态信息的重要性权重，并将其对应的图$\mathcal{G}_s$的先验概率设置为$ P(\mathcal{G}_s) $，则数据$u_i$和$u_j$的联合概率分布可以通过$ \bar{w}_{i,j}= P(u_i, u_j) = \sum_k P(\mathcal{G}_s) P(u_i, u_j|\mathcal{G}_s) $，即可以构建统一的相似性矩阵：
\begin{equation}
\bar{{W}} = \sum_k P(\mathcal{G}_s)\bar{{W}}_s, 
\label{eq3:unifiedW}
\end{equation}
以及相应的统一的权重矩阵$ \bar{{D}}$（其中$ \bar{d}_{i,i} = P(u_i) =\sum_i \bar{w}_{i,j}$）和拉普拉斯矩阵$ \bar{{L}} = \bar{{D}}-\bar{{W}}$

在该设定下的竖直方向传播的优化问题为
\begin{equation}
\mathop{\mathrm{min}}_{{F_v}}\; \frac{1}{2}\eta\; \mathrm{tr}(({F_v}-{Y})^T\bar{{D}}({F_v}-{Y})) +\frac{1}{2}\mathrm{tr}({F_v}^T \bar{{L}}{F_v}),
\label{eq3:MMCP-v}
\end{equation}
相应的水平传播可写为
\begin{equation}
\mathop{\mathrm{min}}_{\mathbf{F_h}}\;\frac{1}{2}\eta \;\mathrm{tr}( ({F_h}-{Y})\bar{{D}}({F_h}-{Y})^T)+\frac{1}{2}\mathrm{tr}({F_h} \bar{{L}}{F_h}^T),
\label{eq3:MMCP-h}
\end{equation}
其中$ \eta > 0  $为正则化参数。

通过求解上述问题，我们可以得到两个闭式解。根据公式（\ref{eq3:MMCP-v}）有
\begin{equation}
{F_v} = \eta(\eta \bar{{D}}+\bar{{L}})^{-1}\bar{{D}}{Y},
\label{eq3:sol-v}
\end{equation}
而根据公式（\ref{eq3:MMCP-h}）则有
\begin{equation}
{F_v} = \eta {Y}\bar{{D}}(\eta \bar{{D}}+\bar{{L}})^{-1}.
\label{eq3:sol-h}
\end{equation}

与公式（\ref{eq3:e2cp}）相似，通过合并竖直方向传播和水平方向传播，我们可以得到最终的传播结果：
\begin{equation}
{F} = \eta^2(\eta\bar{{D}}+\bar{{L}})^{-1}{\bar{{D}} Y\bar{{D}}}(\eta\bar{{D}}+\bar{{L}})^{-1}.
\label{}
\end{equation}

\subsection{多模态融合}
在本节中，首先我们将在约束传播中引入松弛权重组合（Relaxed Weight Combination，RWC）作为基线方法，然后展示我们所提出了MFL（Multi-modal Fusion Learning）方法。
\subsection{松弛权重组合}
\label{sec3:rwc}

\begin{figure}[t]
	\centering
	\bisubcaptionbox{Corel 5k数据集}%
					{Corel 5k dataset}
					[0.49\textwidth]{\includegraphics[width=0.49\textwidth]{chap3/corel_RWC_nmi.eps}
                    \label{fig3:rwc_corel}}
	\bisubcaptionbox{PASCAL VOC'07数据集}%
					{PASCAL VOC'07 dataset}
					[0.49\textwidth]{\includegraphics[width=0.49\textwidth]{chap3/voc_RWC_nmi.eps}
                    \label{fig3:rwc_voc}}
	\bicaption{在Corel 5k数据集和PASCAL VOC'07数据集上，参数$\gamma$在不同的模态数量下对约束聚类效果的影响}{The influence of $ \gamma $ on Corel 5k and PASCAL VOC'07 datasets with different number of  modalities}
	\label{fig3:rwc}
\end{figure}

RWC方法在多模态聚类和多模态标签传播问题较为普遍\cite{wang2009unified,xu2016discriminatively,xu2014multi}。 在通用的标签传播框架内，RWC方法可以被描述为以下优化问题：
\begin{equation}
\begin{split}
\mathop{\mathrm{min}}_{{f},{\alpha}}\;g({f},{\alpha})=&\frac{1}{2}\eta\; \|{f}-{y}\|^2_2+\frac{1}{2}{f}^T \sum_s(\alpha_s)^\gamma{\bar{{L}}}_s{f}, \\
s.t.\;&\sum_s \alpha_s = 1;\\
&\;\alpha_s \ge 0,
\end{split}
\label{eq3:labelpro}
\end{equation}
此处，向量$ {y} \in  \mathbb{R}^{n} $为观测到的类标签信息，向量$ {\alpha} \in  \mathbb{R}^m$为可学习的模态权重（$m$为不同的模态数量），$ {f} \in  \mathbb{R}^{n}$为标签传播的估计结果，$ \gamma > 1$ 和$ \eta $ 是手动设定的参数。拉普拉斯矩阵$ \bar{{L}}_s $ 由公式（\ref{eq3:jointW}）中的 $ \bar{{W}}_s $  及其相应的权重矩阵 $ \bar{{D}}_s $生成。在固定$f$的情况下，我们可以忽略公式（\ref{eq3:labelpro}）中的第一项，并通过拉格朗日函数求解$ {\alpha} $
\begin{equation}
L({\alpha})=\sum_s(\alpha_s)^\gamma{f}^T {\bar{{L}}}_s{f} - \lambda ( \sum_s \alpha_s - 1)-\sum_s \mu_s \alpha_s,
\label{eq3:labelpro_L}
\end{equation}
其中$\lambda$和$\mu_s$为拉格朗日乘子，并且有$ \mu_s \ge 0$，$ \mu_s\alpha_s=0$。令函数\eqref{eq3:labelpro_L}对$ \alpha_s $的导数为零，我们能够得到
\begin{equation}
\gamma \alpha_s^{\gamma-1}{f}^T {\bar{{L}}}_s{f} =\lambda + \mu_s.
\label{eq3:labelpro_L_der}
\end{equation}